{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "area_templates.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q56IgEQ9YKNv",
        "outputId": "66c9e453-549f-4e87-99ff-e6a4ee39eea2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9nbjJau15vk",
        "outputId": "d8d2fec9-a3d7-420d-eff8-41640534d5c4"
      },
      "source": [
        "%env HOME=/content/drive/MyDrive/\n",
        "#!mkdir -p ~/Research/huggingface\n",
        "%cd ~/Research/ner/area_templates/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: HOME=/content/drive/MyDrive/\n",
            "/content/drive/MyDrive/Research/ner/area_templates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUR1v33DCDxL",
        "outputId": "cc6a507e-480b-4217-a2a7-54f8e043faad"
      },
      "source": [
        "%cd ~/Research/ner/DSTC10_evaluation/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Research/ner/DSTC10_evaluation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsORB6JiZGE_",
        "outputId": "7d126cd3-12ae-49c6-8438-d824bcad0b15"
      },
      "source": [
        "!pip install fastDamerauLevenshtein\n",
        "!pip install num2words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastDamerauLevenshtein\n",
            "  Using cached fastDamerauLevenshtein-1.0.7-cp37-cp37m-linux_x86_64.whl\n",
            "Installing collected packages: fastDamerauLevenshtein\n",
            "Successfully installed fastDamerauLevenshtein-1.0.7\n",
            "Collecting num2words\n",
            "  Using cached num2words-0.5.10-py3-none-any.whl (101 kB)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words) (0.6.2)\n",
            "Installing collected packages: num2words\n",
            "Successfully installed num2words-0.5.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6xZCbMqZQlG"
      },
      "source": [
        "import json\n",
        "f1 = open('/content/drive/MyDrive/Research/ner/DSTC10_evaluation/DSTC10_task2_log_eval_phon_templates.json', 'r')\n",
        "log = json.load(f1)\n",
        "f1.close()\n",
        "\n",
        "f2 = open('/content/drive/MyDrive/Research/ner/alexa-with-dstc10-track2-dataset/task1/data/db.json','r')\n",
        "db = json.load(f2)\n",
        "f2.close()\n",
        "\n",
        "f3 = open('/content/drive/MyDrive/Research/ner/DSTC10_track2_task2_log_phon_templates.json','r')\n",
        "log2 = json.load(f3)\n",
        "f3.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV_3vHN0Y7PV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4b267c3-f133-4187-b906-50cfa477e110"
      },
      "source": [
        "#%%writefile BabyTrie_DSTC10_v6_area.py\n",
        "import re\n",
        "import json\n",
        "from fastDamerauLevenshtein import damerauLevenshtein as dl\n",
        "from num2words import num2words\n",
        "from simple_tokenize import Clean_Text\n",
        "from simple_tokenize import Word_Tokenize\n",
        "from extra_methods import simple_num2words\n",
        "\n",
        "class BabyTrie:#baby version of Trie\n",
        "    class TrieNode:#Node within a Trie\n",
        "        def __init__(self,entity=None):\n",
        "            self.children={}#dictionary of TrieNodes\n",
        "            self.markers=[]#list of markers/categories\n",
        "            self.end=False#the Node is leaf, or end of word\n",
        "            self.entity=None#in case needed\n",
        "            self.id=None\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.root=self.new_node()\n",
        "\n",
        "    def new_node(self,word=None):\n",
        "        #Creates TrieNode object with a given word\n",
        "        return self.TrieNode(word)\n",
        "\n",
        "    def restricted_insert(self,lst,cat,number = -1):\n",
        "        if len(lst) == 0:\n",
        "            print(\"ERROR: empty NE in knowledge file\")\n",
        "            return\n",
        "        if len(lst) == 1 and lst[0]==cat:\n",
        "            print(\"only one elem in lst\")\n",
        "            return\n",
        "        \n",
        "        if lst[0]=='the':#the is ambiguous\n",
        "            lst.pop(0)\n",
        "\n",
        "        ptr=self.root\n",
        "        for i in range(0,len(lst)):#for every elem but not the last (since it is the category)\n",
        "            if lst[i] not in ptr.children.keys():#if already a key, skip; else add new\n",
        "                new=self.new_node(lst[i])\n",
        "                ptr.children[lst[i]]=new\n",
        "            ptr=ptr.children[lst[i]]\n",
        "        #if (len(lst)==2 and lst[-2] in ['good','ask','page']):#we dont want to treat good or ask as an entity (see test.txt)\n",
        "            #ptr.end=False\n",
        "        if (len(lst)==3 and lst[-3]=='cable' and lst[-2]=='car'):\n",
        "            ptr.end=False\n",
        "        else:\n",
        "            ptr.end=True#is end of word\n",
        "            ptr.id=number\n",
        "        if cat not in ptr.markers:#Only adds new categories to the list of markers \n",
        "            ptr.markers.append(cat)\n",
        "    \n",
        "    def insert(self,lst,cat,number):\n",
        "        if len(lst) == 0:\n",
        "            print(\"ERROR: empty NE in knowledge file\")\n",
        "            return\n",
        "        if len(lst) == 1 and lst[0]==cat:\n",
        "            print(\"only one elem in lst\")\n",
        "            return\n",
        "        \n",
        "        if lst[0]=='the':#the is ambiguous\n",
        "            lst.pop(0)\n",
        "        \n",
        "        \n",
        "        \n",
        "        if lst[-1]!=cat: #['a','and','b'] + ['restaurant']\n",
        "            lst.append(cat)\n",
        "        ptr=self.root\n",
        "        for i in range(0,len(lst)-1):#for every elem but not the last (since it is the category)\n",
        "            if lst[i] not in ptr.children.keys():#if already a key, skip; else add new\n",
        "                new=self.new_node(lst[i])\n",
        "                ptr.children[lst[i]]=new\n",
        "            ptr=ptr.children[lst[i]]\n",
        "        if (len(lst)==2 and lst[-2] in ['good','ask','page']):#we dont want to treat good or ask as an entity (see test.txt)\n",
        "            ptr.end=False\n",
        "        elif (len(lst)==3 and lst[-3]=='cable' and lst[-2]=='car'):\n",
        "            ptr.end=False\n",
        "        else:\n",
        "            ptr.end=True#is end of word\n",
        "            ptr.id=number\n",
        "        if cat not in ptr.markers:#Only adds new categories to the list of markers \n",
        "            ptr.markers.append(cat)\n",
        "        if lst[-1] not in ptr.children.keys():#avoid possible conflict with same name\n",
        "            new=self.new_node(lst[-1])\n",
        "            ptr.children[lst[-1]]=new#adds the category as one of the leaf node\n",
        "        ptr=ptr.children[lst[-1]]\n",
        "        ptr.end=True\n",
        "        ptr.id=number\n",
        "        if cat not in ptr.markers:#only adds category if not in list of markers\n",
        "            ptr.markers.append(cat)\n",
        "    \n",
        "    def isinTrie(self,sen):\n",
        "        stutter_match=False\n",
        "        dl_mistakes=['train','want','american','lane','fees','fee','marina','wanna','canna','dinna','finna']\n",
        "        #outfile for tracking log process\n",
        "        dic={}#the uncleaned version of returned dictionary\n",
        "        flag=False#=True when a phrase in the sentence does not match the trie anymore\n",
        "        lst=[]#the list that will ultimately be returned\n",
        "\n",
        "        new_sen=sen.lower().strip()#cleans up sentence\n",
        "\n",
        "        lst=Word_Tokenize(Clean_Text(new_sen))\n",
        "        \n",
        "        last=len(lst)-1#keep track of last to ensure index does not go over limit\n",
        "        #the returned list is completely formed at this point, we use it to generate dictionary\n",
        "        rstart=0#starting position of NE\n",
        "        rend=0#ending position of NE\n",
        "\n",
        "        proceed=False\n",
        "        for i in range(len(lst)):\n",
        "            ptr=self.root\n",
        "            if lst[i] in ptr.children:\n",
        "                proceed=True\n",
        "                rstart=i\n",
        "                ptr=ptr.children[lst[i]]\n",
        "            elif lst[i] not in ptr.children and lst[i] not in dl_mistakes:\n",
        "                for word in ptr.children:\n",
        "                    if len(lst[i])<=4:\n",
        "                        dl_score=dl(lst[i],word,similarity=False,deleteWeight=2,insertWeight=2,replaceWeight=2)\n",
        "                        bm=0\n",
        "                    else:\n",
        "                        dl_score=dl(lst[i],word,similarity=False,deleteWeight=1,insertWeight=2,replaceWeight=2)\n",
        "                        bm=1\n",
        "                    if dl_score<=bm:\n",
        "                        proceed=True\n",
        "                        rstart=i\n",
        "                        ptr=ptr.children[word]\n",
        "                        break\n",
        "            if proceed:\n",
        "                stutter_utt=0\n",
        "                for j in range(i+1,len(lst)):\n",
        "                    if lst[j] in ptr.children:\n",
        "                        ptr=ptr.children[lst[j]]\n",
        "                        rend=j\n",
        "                        stutter_match=False\n",
        "                    elif lst[j] not in ptr.children:\n",
        "                        proceed=False\n",
        "                        for word in ptr.children:\n",
        "                            dl_score=dl(lst[j],word,similarity=False,deleteWeight=2,insertWeight=2,replaceWeight=2)\n",
        "                            bm=1\n",
        "                            if dl_score<=bm and lst[j].isalnum():\n",
        "                                ptr=ptr.children[word]\n",
        "                                rend=j\n",
        "                                proceed=True\n",
        "                                stutter_match=False\n",
        "                                break\n",
        "                        if (len(lst[j])<=3) and (lst[j].isalnum()) and (stutter_utt<1):#allow one mismatch (except for punc), could be stuttering\n",
        "                            stutter_utt+=1\n",
        "                            proceed=True\n",
        "                            rend=j-1\n",
        "                            stutter_match=True\n",
        "                            #here rend not counted since if next is not matched, it will not be effected if the prev word is actually end of word\n",
        "                        elif stutter_match:\n",
        "                            rend=j-2\n",
        "                            break\n",
        "                        #print('for '+lst[i]+' stopped at '+lst[j])#degbug use\n",
        "                        if not proceed:\n",
        "                            rend=j-1\n",
        "                            break\n",
        "\n",
        "            if ptr.end:\n",
        "                for i in range(len(ptr.markers)):\n",
        "                    if (ptr.markers[i] in dic):#if already a key, add to value\n",
        "                        if rstart>rend:\n",
        "                            rend=rstart\n",
        "                        dic[ptr.markers[i]].append(((rstart,rend),ptr.id))\n",
        "                    else:#if not, make new entry\n",
        "                        if rstart>rend:\n",
        "                            rend=rstart\n",
        "                        dic[ptr.markers[i]]=[((rstart,rend),ptr.id)]\n",
        "                rstart=0\n",
        "                rend=0\n",
        "            else:\n",
        "                continue\n",
        "        #cleaning up dictionary\n",
        "        rdic={}#clean version of the dictionary that is ultimately returned\n",
        "        for cat in dic.keys():\n",
        "            rdic[cat]=[]\n",
        "            rlst=sorted(dic[cat],key=lambda item:item[0][1]-item[0][0],reverse=True)\n",
        "            #rdic[cat].append(rlst[0])\n",
        "            for i in range(0,len(rlst)):\n",
        "                rflag=True\n",
        "                for rcat in rdic.keys():#make sure no overlap: ex. 'some hotel diner' > 'some hotel'\n",
        "                    for elem in rdic[rcat]:\n",
        "                        if (rlst[i][0][0]<elem[0][0] and rlst[i][0][1]<elem[0][0]):#ex. if we have (3,5) we can take (1,2)\n",
        "                            continue\n",
        "                        elif (rlst[i][0][0]>elem[0][1] and rlst[i][0][1]>elem[0][1]):#ex. if we have (3,5) we can take (6,7)\n",
        "                            continue\n",
        "                        else:# any equals, [0] or [1] will not work: ex. we have (3,5). cannot have (3,4) or (4,5).\n",
        "                            if rlst[i][0][1]-rlst[i][0][0]==elem[0][1]-elem[0][0] and rlst[i][0][1]>elem[0][1]:\n",
        "                                rdic[rcat].remove(elem)\n",
        "                                continue\n",
        "                            else:\n",
        "                                rflag=False\n",
        "                if rflag:\n",
        "                    rdic[cat].append(rlst[i])\n",
        "        del_lst=[]#cheap(costly) way to deal with empty dic entry\n",
        "        for cat in rdic:\n",
        "            if len(rdic[cat])==0:\n",
        "                del_lst.append(cat)\n",
        "        for elem in del_lst:\n",
        "            del rdic[elem]\n",
        "        return (lst,rdic)\n",
        "\n",
        "    def initialize_area(self,dic):#add db_dic if-/>\n",
        "        #extract ref knowledge from db_dic TBDDDDDDDDDD\n",
        "        #start of initialization\n",
        "        dig=False\n",
        "        chain_entities={}#keeping track of chain restaurants' ids i.e. {'entity name':('cat','id1|id2|id3|...')}\n",
        "        for cat in dic.keys():\n",
        "            for record in dic[cat]:\n",
        "\n",
        "                if ('area' in record and record['area'] is not None):\n",
        "                    new_name=record['area'].lower().strip()#cleans up name\n",
        "                    if new_name == cat:\n",
        "                        print('exceptional entity---------------------')\n",
        "                        continue\n",
        "                    lst=[]#final list that is used to insert into bt\n",
        "                    dlst=[]\n",
        "                    alt_dlst=[]\n",
        "                    no_punc_lst=[]\n",
        "                    plst=Word_Tokenize(Clean_Text(new_name))\n",
        "                    #p=re.compile(r\"^(\\w+)(\\'\\w+)$\")\n",
        "\n",
        "                    for i in range (len(plst)):\n",
        "                        if plst[i].isnumeric():\n",
        "                            dig=True\n",
        "                            for alt_dig in plst[i]:\n",
        "                                alt_dlst.append(simple_num2words(int(alt_dig)))\n",
        "\n",
        "                            converted=num2words(plst[i])\n",
        "                            if '-' in converted:\n",
        "                                converted_lst=converted.split('-')\n",
        "                                for digword in converted_lst:\n",
        "                                    dlst.append(digword)\n",
        "                            else:\n",
        "                                converted_lst=converted.split()\n",
        "                                for digword in converted_lst:\n",
        "                                    dlst.append(digword)\n",
        "                            lst.append(plst[i])\n",
        "                            continue\n",
        "                        else:\n",
        "                            lst.append(plst[i])\n",
        "                            dlst.append(plst[i])\n",
        "                            alt_dlst.append(plst[i])\n",
        "                    self.restricted_insert(lst,'area','-1')\n",
        "                    #self.restricted_insert(no_punc_lst,cat,elem)#'alpha-milton guest house'\n",
        "\n",
        "                    if dig:\n",
        "                        self.restricted_insert(dlst,'area','-1')\n",
        "                        self.restricted_insert(alt_dlst,'area','-1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /content/drive/MyDrive/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sxssU-jdpfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "895525b8-e3f5-4608-c300-bd4cda44d0b0"
      },
      "source": [
        "bt = BabyTrie()\n",
        "bt.initialize_area(db)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n",
            "ERROR: empty NE in knowledge file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz-6hV9teHSL",
        "outputId": "c25f0964-c3bd-4c9d-8f18-286e18057932"
      },
      "source": [
        "bt.isinTrie(\"Fisherman's Wharf baby\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['fisherman', \"'s\", 'wharf', 'baby'], {'area': [((0, 2), '-1')]})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBxUE1f5eTdb"
      },
      "source": [
        "def gettemplate_area_map(title):\n",
        "    word_lst,ind_dic = bt.isinTrie(title)\n",
        "    nlst = Word_Tokenize(Clean_Text(title))\n",
        "    new_sen = title.strip()#cleans up sentence\n",
        "    en_dic={}\n",
        "\n",
        "    n = 1\n",
        "    for key in ind_dic:\n",
        "        ind_lst=ind_dic[key]\n",
        "        for pair in ind_lst:\n",
        "            temp_str=''\n",
        "            for index in range(pair[0][0],pair[0][1]+1):\n",
        "                if not nlst[index][0].isalnum():\n",
        "                    temp_str=temp_str[:-1]\n",
        "                if nlst[index]=='-':\n",
        "                    temp_str+=nlst[index]\n",
        "                else:\n",
        "                    temp_str+=nlst[index]+' '\n",
        "            temp_str=temp_str[:-1]#getting rid of last space\n",
        "            #temp_str_converted=convert_text2num(temp_str)#name entity to be in dig form\n",
        "            en_dic['<'+key+'-'+str(n)+'>']=temp_str\n",
        "            title=title.replace(temp_str,'<'+key+'-'+str(n)+'>')\n",
        "            n += 1\n",
        "    return [title,en_dic]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx6ngGpefH9d"
      },
      "source": [
        "for dialogue in log2:\n",
        "    for turn in dialogue:\n",
        "        area_template, area_map = gettemplate_area_map(turn['template'])\n",
        "        turn['area_template'] = area_template\n",
        "        turn['area_map'] = area_map\n",
        "out = open('DSTC10_task2_log_template_warea.json','w')\n",
        "json.dump(log2, out, indent = 4)\n",
        "out.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}